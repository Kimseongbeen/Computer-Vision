{"cells":[{"cell_type":"markdown","metadata":{"id":"e8UGuwMsPQlC"},"source":["# **Single Shot Detectors (SSDs) with OpenCV**\n","\n","####**In this lesson we'll learn how to use pre-trained models to implement an SSD in OpenCV**\n","\n","Source - https://github.com/datitran/object_detector_app/tree/master/object_detection"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17879,"status":"ok","timestamp":1716370849878,"user":{"displayName":"김성빈","userId":"06189190876431521814"},"user_tz":-540},"id":"U9CKEe3bMlJO","outputId":"9a9678b3-f946-42d9-9924-e6cfa876f6af"},"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.10/dist-packages/gdown/__main__.py:132: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n","  warnings.warn(\n","Downloading...\n","From (original): https://drive.google.com/uc?id=1O2uCujErifjvK1ziRGssaQO9khI15g6q\n","From (redirected): https://drive.google.com/uc?id=1O2uCujErifjvK1ziRGssaQO9khI15g6q&confirm=t&uuid=9336a4a3-9874-4135-a0f7-345446e13df2\n","To: /content/images.zip\n","100% 29.6M/29.6M [00:00<00:00, 82.4MB/s]\n","/usr/local/lib/python3.10/dist-packages/gdown/__main__.py:132: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n","  warnings.warn(\n","Downloading...\n","From: https://drive.google.com/uc?id=1I242ygNivRhYJ6kIEfvlAhg_2WMTgDDv\n","To: /content/SSDs.zip\n","100% 25.5M/25.5M [00:00<00:00, 27.9MB/s]\n","replace images/castara.jpeg? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n","replace SSDs/frozen_inference_graph.pb? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n"]}],"source":["# Our Setup, Import Libaries, Create our Imshow Function and Download our Images\n","import cv2\n","import numpy as np\n","from matplotlib import pyplot as plt\n","\n","# Define our imshow function\n","def imshow(title = \"Image\", image = None, size =12):\n","    w, h = image.shape[0], image.shape[1]\n","    aspect_ratio = w/h\n","    plt.figure(figsize=(size * aspect_ratio,size))\n","    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n","    plt.title(title)\n","    plt.show()\n","\n","# Download and unzip our images\n","!gdown --id 1O2uCujErifjvK1ziRGssaQO9khI15g6q\n","!gdown --id 1I242ygNivRhYJ6kIEfvlAhg_2WMTgDDv\n","!unzip -qq images.zip\n","!unzip -qq SSDs.zip"]},{"cell_type":"markdown","metadata":{"id":"HVsxy8E-Mnyj"},"source":["We use a TensorFlow model from TensorFlow object detection model zoo may be used to detect objects from 90 classes:\n","http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v1_coco_11_06_2017.tar.gz\n","\n","Text graph definition must be taken from opencv_extra:\n","https://github.com/opencv/opencv_extra/tree/master/testdata/dnn/ssd_mobilenet_v1_coco.pbtxt\n"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1u33UCofwR0pkNFXLfnWujXIb5nHNXukD"},"executionInfo":{"elapsed":4610,"status":"ok","timestamp":1716371588927,"user":{"displayName":"김성빈","userId":"06189190876431521814"},"user_tz":-540},"id":"OmCCnhW2Kvzb","outputId":"0f0141ab-878e-49f6-b8ab-947644d271af"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["# Load our images\n","# frame = cv2.imread('./images/elephant.jpg')\n","# frame = cv2.imread('./images/Volleyball.jpeg')\n","# frame = cv2.imread('./images/coffee.jpg')\n","frame = cv2.imread('./images/hilton.jpeg')\n","# frame = cv2.imread('./images/tommys_beers.jpeg')\n","imshow(\"original\", frame)\n","\n","print(\"Running our Single Shot Detector on our image...\")\n","# Make a copy of our loaded image\n","image = frame.copy()\n","\n","# Set the widths and heights that are needed for input into our model\n","inWidth = 300\n","inHeight = 300\n","WHRatio = inWidth / float(inHeight)\n","\n","# These are needed for our preprocessing of our image\n","inScaleFactor = 0.007843\n","meanVal = 127.5\n","\n","# Point to the paths of our weights and  model architecture in a protocol buffer\n","prototxt = \"SSDs/ssd_mobilenet_v1_coco.pbtxt\"\n","weights = \"SSDs/frozen_inference_graph.pb\"\n","\n","# Number of classes\n","num_classes = 90\n","\n","# Probality Threshold\n","thr = 0.5\n","\n","net = cv2.dnn.readNetFromTensorflow(weights, prototxt)\n","\n","swapRB = True\n","classNames = { 0: 'background',\n","    1: 'person', 2: 'bicycle', 3: 'car', 4: 'motorcycle', 5: 'airplane', 6: 'bus',\n","    7: 'train', 8: 'truck', 9: 'boat', 10: 'traffic light', 11: 'fire hydrant',\n","    13: 'stop sign', 14: 'parking meter', 15: 'bench', 16: 'bird', 17: 'cat',\n","    18: 'dog', 19: 'horse', 20: 'sheep', 21: 'cow', 22: 'elephant', 23: 'bear',\n","    24: 'zebra', 25: 'giraffe', 27: 'backpack', 28: 'umbrella', 31: 'handbag',\n","    32: 'tie', 33: 'suitcase', 34: 'frisbee', 35: 'skis', 36: 'snowboard',\n","    37: 'sports ball', 38: 'kite', 39: 'baseball bat', 40: 'baseball glove',\n","    41: 'skateboard', 42: 'surfboard', 43: 'tennis racket', 44: 'bottle',\n","    46: 'wine glass', 47: 'cup', 48: 'fork', 49: 'knife', 50: 'spoon',\n","    51: 'bowl', 52: 'banana', 53: 'apple', 54: 'sandwich', 55: 'orange',\n","    56: 'broccoli', 57: 'carrot', 58: 'hot dog', 59: 'pizza', 60: 'donut',\n","    61: 'cake', 62: 'chair', 63: 'couch', 64: 'potted plant', 65: 'bed',\n","    67: 'dining table', 70: 'toilet', 72: 'tv', 73: 'laptop', 74: 'mouse',\n","    75: 'remote', 76: 'keyboard', 77: 'cell phone', 78: 'microwave', 79: 'oven',\n","    80: 'toaster', 81: 'sink', 82: 'refrigerator', 84: 'book', 85: 'clock',\n","    86: 'vase', 87: 'scissors', 88: 'teddy bear', 89: 'hair drier', 90: 'toothbrush' }\n","\n","# Create our input image blob required for input into our network\n","blob = cv2.dnn.blobFromImage(frame, inScaleFactor, (inWidth, inHeight), (meanVal, meanVal, meanVal), swapRB)\n","net.setInput(blob)\n","\n","# Pass our input image/blob into the network\n","detections = net.forward()\n","\n","# Crop frame if needed as we don't resize our input but take a square input\n","cols = frame.shape[1]\n","rows = frame.shape[0]\n","\n","if cols / float(rows) > WHRatio:\n","    cropSize = (int(rows * WHRatio), rows)\n","else:\n","    cropSize = (cols, int(cols / WHRatio))\n","\n","y1 = int((rows - cropSize[1]) / 2)\n","y2 = y1 + cropSize[1]\n","x1 = int((cols - cropSize[0]) / 2)\n","x2 = x1 + cropSize[0]\n","frame = frame[y1:y2, x1:x2]\n","\n","cols = frame.shape[1]\n","rows = frame.shape[0]\n","\n","# Iterate over every detection\n","for i in range(detections.shape[2]):\n","    confidence = detections[0, 0, i, 2]\n","    # Once confidence is greater than the threshold we get our bounding box\n","    if confidence > thr:\n","        class_id = int(detections[0, 0, i, 1])\n","\n","        xLeftBottom = int(detections[0, 0, i, 3] * cols)\n","        yLeftBottom = int(detections[0, 0, i, 4] * rows)\n","        xRightTop   = int(detections[0, 0, i, 5] * cols)\n","        yRightTop   = int(detections[0, 0, i, 6] * rows)\n","\n","        # Draw our bounding box over our image\n","        cv2.rectangle(frame, (xLeftBottom, yLeftBottom), (xRightTop, yRightTop),\n","                      (0, 255, 0), 3)\n","        # Get our class names and put them on our image (using a white background)\n","        if class_id in classNames:\n","            label = classNames[class_id] + \": \" + str(confidence)\n","            labelSize, baseLine = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n","\n","            yLeftBottom = max(yLeftBottom, labelSize[1])\n","            cv2.rectangle(frame, (xLeftBottom, yLeftBottom - labelSize[1]),\n","                                 (xLeftBottom + labelSize[0], yLeftBottom + baseLine),\n","                                 (255, 255, 255), cv2.FILLED)\n","            cv2.putText(frame, label, (xLeftBottom, yLeftBottom),\n","                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0))\n","\n","# Show our detections\n","imshow(\"detections\", frame)"]},{"cell_type":"markdown","metadata":{"id":"ioK2cYiLUsIO"},"source":["**Find other pretrained models here** - https://github.com/tensorflow/models/tree/master/research/object_detection/samples/configs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XOvhwq_kRB5Q"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}